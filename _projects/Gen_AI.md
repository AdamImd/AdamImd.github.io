---
layout: page
title:  Zero-Shot Robotic Manipulation
description: We predict video sequences of robot interactions using pre-trained video diffusion models and use these predictions to plan actions.
img: assets/img/GenAI/WAN.webp
importance: 3
category: work
---

# Overview

We predict video sequences of robot interactions using pre-trained video diffusion models and use these predictions to plan actions. This enable zero-shot manipulation policy learning approach that leverages large-scale video diffusion models without any additional training.

<!-- Add the GIF -->
<div class="row justify-content-center">
    <div class="col-sm-10 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/GenAI/WAN.webp" title="Zero-Shot Robotic Manipulation using Video Diffusion Models" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Prompt: "Untie the knot". 
</div>

We utilize pre-trained video diffusion models (WAN) to generate future video frames conditioned on the current observation and a text prompt giving the desired action. We then use these predicted video sequences to plan robot actions with a Diffusion Policy. This approach allows us to perform various manipulation tasks without any task-specific training, demonstrating the potential of large-scale video diffusion models for zero-shot robotic manipulation.

<!-- arch.png -->
<div class="row justify-content-center">
    <div class="col-sm-10 mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/GenAI/arch.png" title="System Architecture" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

The Diffusion Policy takes as input the current observation, along with a feature that encodes the predicted video frames from the WAN model. The feature is generated by using the current observation as the query and the predicted video frames as the keys and values in a cross-attention mechanism. The Diffusion Policy then generates a sequence of robot actions that are expected to lead to the desired outcome as seen in the predicted video frames.




# Proposal PDF
<!-- Link to: assets/img/GenAI/VideoEmbodiment_EE8520_F25-1.pdf -->
For more details, please refer to our [project proposal](assets/pdf/VE.pdf).
